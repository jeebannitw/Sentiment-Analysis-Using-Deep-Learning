{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify the Sentiment - Is the Tweet a Hate Speech ?\n",
    "\n",
    "# Motivation\n",
    "Hate  speech  is  an  unfortunately  common  occurrence  on  the  Internet.  Often social media sites like Facebook and Twitter face the problem of identifying and censoring  problematic  posts  while weighing the right to freedom of speech. The  importance  of  detecting  and  moderating hate  speech  is  evident  from  the  strong  connection between hate speech and actual hate crimes. Early identification of users promoting  hate  speech  could  enable  outreach  programs that attempt to prevent an escalation from speech to action. Sites such as Twitter and Facebook have been seeking  to  actively  combat  hate  speech. In spite of these reasons, NLP research on hate speech has been very limited, primarily due to the lack of a general definition of hate speech, an analysis of its demographic influences, and an investigation of the most effective features.\n",
    "\n",
    "### Data\n",
    "#### View of  Good Tweets\n",
    "![Postive  Data Sample](pos_sample.png)\n",
    "#### View of Bad Tweets\n",
    "![Negative  Data Sample](neg_sample.png)\n",
    "The Data has about 7% of Positive sample\n",
    "\n",
    "## Basic Text Pre Processing \n",
    "1. Converting the tweets to lowercase\n",
    "2. Drop Non Alphabets\n",
    "3. Drop URLs\n",
    "4. Drop stop words\n",
    "5. lemmatization of words \n",
    "6. Drop unwanted words to remove noise(user defined words like '@usres','aaaaa','zzz','etc')\n",
    "\n",
    "### Feature Extraction From Text\n",
    "- #### Meta Features\n",
    "    - Number of words used in a Tweet\n",
    "    - Length of the Tweet\n",
    "    - Polarity Score of the Tweet\n",
    "    - Avg length of words used\n",
    "    - ....\n",
    "- #### Vector Space Features\n",
    "    - Count Vectorizer(It returns count of the terms present in the document in sparse format)\n",
    "    - TF-IDF Vectorizer (It returns term frequency multiplied with Inverse document frequency in sparse format)\n",
    "    - Word Embeddings (It transforms each words to a neumerical vector received from word2vec learning which used as features for NLP task)\n",
    "    \n",
    "##### Example Count vectorizer \n",
    "![Count Vectorizer](count_vec.png)\n",
    "##### Example TF-IDF vectorizer \n",
    "![TF-IDF Vectorizer](tfidf_vec.png)\n",
    "\n",
    "\n",
    "## Classification Techniques\n",
    "- XGB (Performs well Meta Features)\n",
    "- XGB (Performs well after reducing dimension of sparse TF-IDF  features using PCA or SVD)\n",
    "- SVM or Naive Bayes(Perform well with Sparse TF-IDF or TF features)\n",
    "- LSTM or GRU (Performs well Words Embedding features)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
